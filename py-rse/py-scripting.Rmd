# Command Line Programs in Python {#py-rse-py-scripting}

The Jupyter Notebook, PyCharm and other graphical interfaces
are great for prototyping code and exploring data,
but in many cases we ultimately need to apply our code to thousands of data files,
run it with many different parameters,
or combine it with other programs in a data analysis pipeline.
The easiest way to do this effectively is often
to turn our code into a standalone program that can be run in the Unix shell
just like other command-line tools [@Tasc2017].

In this chapter we will develop a command-line Python program
that can be controlled by several option flags,
handles input and output in ways that other command-line tools expect,
and provides useful information when things go wrong.
The result will have more scaffolding than useful application code,
but that scaffolding stays more or less the same as programs get larger.

## How can I tell if my code is a program or a module? {#py-rse-py-scripting-main}

If we are going to create a Python program that can run from the command line,
the first thing we should do is to add the following to the bottom of the file.

```python
if __name__ == '__main__':
```

This line differentiates between
running a Python file as a standalone program
and importing it as a module.
When we import a Python file as a module in another program,
the `__name__` variable is automatically set to the name of the file.
When we run a Python file as a standalone program,
on the other hand,
`__name__` is always set to the special string `"__main__"`.
To illustrate this,
let's create the file `print_name.py`
that prints the value of the `__name__` variable:

```python
print(__name__)
```

When we run this file directly,
it will print `__main__`:

```shell
$ python print_name.py
```

But if we import `print_name.py` from another file
or from the Python interpreter,
it will print the name of the file,
i.e. `print_name`.

```shell
$ python
Python 3.8.1 | packaged by conda-forge | (default, Jan 29 2020, 14:55:04)
[GCC 7.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import print_name
print_name
```

This means that we can separate the two cases above
by checking the value of the variable `__name__`.
If that tells us that the file is running as a standalone program,
we can then handle command-line options, print help, or whatever else is appropriate.
We could put the main program code directly under the `if` statement,
but that's generally considered bad practice,
since it makes testing harder.
Instead,
we define this functionality inside a function conventionally called `main`,
but we can call it whatever we want.
So instead of writing out code like this:

```python
if __name__ == "__main__":
    # code goes here
```

We write it like this

```python
def main():
    # code goes here


if __name__ == "__main__":
    main()
```


> **Quickly running short Python statements**
>
> We don't need to open the interactive interpreter to run Python statements.
> Instead,
> we could invoke Python with the command flag and the quoted statement:
>
>```
>$ python -c "import print_name"
>print_name
>```
`

## How can I handle command-line options? {#py-rse-py-scripting-options}

The next thing we need is
a library to parse any options given to the program on the command line.
The most commonly used library in Python is [`argparse`][argparse],
which can handle options with or without arguments,
convert those arguments from strings to numbers or other types,
display help,
and many other things.

The simplest way to explain how `argparse` works is by example,
so let's create a short Python script called `script_template.py`:

```python
"""One-line description of what the script does."""
import argparse


def main(args):
    """Run the program."""
    print('Input file:', args.infile)
    print('Output file:', args.outfile)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('infile', type=str, help='Input file name')
    parser.add_argument('outfile', type=str, help='Output file name')
    args = parser.parse_args()
    main(args)
```

If we examine the contents of `script_template.py` we can see that if it is run
as a standalone program at the command line
(i.e. if `__name__ == '__main__'` is true) then the script goes ahead and uses
the `argparse` library to create an argument parser.
In this case the description of the program for the help information is set to `__doc__`,
which is the character string provided in the very first line of the script.
Two command line arguments are then defined:
an input file name (`infile`) and output file name (`outfile`).
The script parses the command line to get those arguments using `parse_args()`,
stores them in an `argparse.Namespace` object,
which we assign to the variable `args`
and pass on to the `main` function.
The main function then retrieves the arguments from the `argparse.Namespace` object
by calling `args.infile` and `args.outfile`.

If we go ahead and run `script_template.py` at the command line
we can see that `argparse` has successfully handled the input arguments:

```shell
$ python script_template.py in.csv out.png
```

```text
Input file: in.csv
Output file: out.png
```

It also issues errors when users give the program invalid arguments:

```shell
$ python script_template.py in.csv
```

```text
usage: script_template.py [-h] infile outfile
script_template.py: error: the following arguments are required: outfile
```

and automatically generates help information:

```shell
$ python script_template.py -h
```

```text
usage: script_template.py [-h] infile outfile

One-line description of what the script does.

positional arguments:
  infile      Input file name
  outfile     Output file name

optional arguments:
  -h, --help  show this help message and exit
```


## A practical example: Zipf's Law analysis {#py-rse-py-scripting-example}

### Counting words

Now that we've got a template for creating Python scripts,
we can go ahead and apply it to the problem of counting words
(and ultimately verifying Zipf's Law) in our collection of classic English novels.

```shell
$ cd ~/zipfs-law/bin
```

To start,
here's a function that uses the regular expressions (`re`) library
to identify all the words in a text file and a counter function
from the `collections` library to tally up the occurrences of each word.

```python
import re
from collections import Counter


def count_words(reader):
    """Count the occurrence of each word in a string."""
    text = reader.read()
    findwords = re.compile(r"\w+", re.IGNORECASE)
    word_list = re.findall(findwords, text)
    word_counts = Counter(word_list)
    return word_counts
```

`\w+` means to match all characters that commonly occur inside words,
such as letters, numbers, and underscores.
Spaces and punctuation are not matched,
so most strings will be split at these characters,
effectively separating the text into individual words.

We can apply that function to the Dracula ebook (for example):

```python
with open('../data/dracula.txt', 'r') as reader:
    word_counts = count_words(reader)
print(word_counts)
```

```text
Counter({'the': 7474, 'and': 5803, 'I': 4846, 'to': 4662, 'of': 3707, 'a': 2955, 'in': 2466, 'that': 2436, 'he': 1996, 'was': 1870, 'it': 1808, 'is': 1498, 'for': 1480, 'as': 1476, 'me': 1452, ...
```

The `open` function takes a file path as a string,
and reads in that file in a format familiar to Python.
This format is commonly referred to as a `file object` or `stream`,
and allows Python to effectively operate on the content of the file.

If we want the word counts in a more familiar format like CSV,
we can write a small function that takes our `collections.Counter` object,
ensures that it orders the words from most to least frequent,
and then writes it out to [standard output][standard output] in csv format:

```python
import csv


def collection_to_csv(collection, ntop=None):
    """Write out a collection of items and counts in csv format."""
    collection = collection.most_common()
    writer = csv.writer(sys.stdout)
    writer.writerows(collection)
```

Running this would output all the words in the book together with their count.
To make the output a little easier to view on our screen,
we can add an option to limit the output to the n most frequent words.

```python
def collection_to_csv(collection, ntop=None):
    """Write out a collection of items and counts in csv format."""
    collection = collection.most_common()
    limit = ntop if ntop else len(collection)
    writer = csv.writer(sys.stdout)
    writer.writerows(collection[0:limit])
```

```python
collection_to_csv(word_counts, ntop=10)
```

```text
the,7474
and,5803
I,4846
to,4662
of,3707
a,2955
in,2466
that,2436
he,1996
was,1870
```

To make our `count_words` and `collection_to_csv` functions available at the command line,
we need to insert them into the script template developed earlier
and call the functions from within the `main` function.
Let's call the script `countwords.py`:

```python
"""Count the occurrences of all words in a text and output them in CSV format."""
import sys
import re
import argparse
import csv
from collections import Counter


def collection_to_csv(collection, ntop=None):
    """Write out a collection of items and counts in csv format."""
    collection = collection.most_common()
    limit = ntop if ntop else len(collection)
    writer = csv.writer(sys.stdout)
    writer.writerows(collection[0:limit])


def count_words(reader):
    """Count the occurrence of each word in a string."""
    text = reader.read()
    findwords = re.compile(r"\w+", re.IGNORECASE)
    word_list = re.findall(findwords, text)
    word_counts = Counter(word_list)
    return word_counts


def main(args):
    """Run the command line program."""
    with args.infile as reader:
        word_counts = count_words(reader)
    collection_to_csv(word_counts, ntop=args.ntop)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('infile', type=argparse.FileType('r'), nargs='?',
                        default='-', help='Input file name')
    parser.add_argument('-n', '--ntop', type=int, default=None,
                        help='Limit output to n most frequent words')
    args = parser.parse_args()
    main(args)
```

In addition to pasting the two new functions and updating our `main` function,
we have changed the argparse options for the `'infile'` arguments.
Setting `type=argparse.FileType('r')`
instructs argparse to read a file and pass on its contents as a file object
(just like `open`),
instead of just passing the file path as a string.
This is why we no longer need to use `open` inside the main function.
Together with `nargs='?'`,
this will allow us to effectively use our script in a pipeline,
as we will see later.

We have also replaced the `'outfile'` argument with an optional `-n` (or `--ntop`) flag
to limit the output so that it's easier to view in our terminal window.
Let's see this in action:

```shell
$ python countwords.py ../data/dracula.txt -n 10
```

```text
the,7474
and,5803
I,4846
to,4662
of,3707
a,2955
in,2466
that,2436
he,1996
was,1870
```

For the `infile` option,
the number of expected arguments (`nargs`) is set to `?`.
This means that one argument (i.e. a file name)
will be consumed from the command line *if possible*.
If we don't provide a file name,
`nargs='?'` dictates that the `default` value of `-` will be used.
The `argparse.FileType('r')` argument type understands the pseudo-argument '-'
to mean standard input and reads from `sys.stdin`.
This means the script can participate in a pipeline like
many of the other command line programs we've met.
For instance,
this pipeline counts the words in the first 500 lines of the book:

```shell
$ head -500 ../data/dracula.txt | python countwords.py --ntop 10
```

```text
the,216
and,123
of,114
I,99
to,82
in,54
a,49
was,42
that,41
it,40
```

Ultimately,
we want to save the word counts to a CSV file for further analysis and plotting,
which we can do via redirection using `>`:

```shell
$ mkdir ../results
```

```shell
$ python countwords.py ../data/dracula.txt > ../results/dracula_words.csv
```

```shell
$ python countwords.py ../data/moby_dick.txt > ../results/moby_dick_words.csv
```

```shell
$ python countwords.py ../data/jane_eyre.txt > ../results/jane_eyre_words.csv
```

> **Positional and optional arguments**
>
> In writing the `countwords.py` script we've met two types of command line arguments.
>
> *Optional arguments* are defined using a leading `-` or `--` (or both),
> such that all three of the following definitions are valid:
> ```python
> parser.add_argument('-f', type=int, help='foo option')
> parser.add_argument('--foo', type=int, help='foo option')
> parser.add_argument('-f', '--foo', type=int, help='foo option')
> ```
> The convention is for `-` to precede a "short" single letter option
> and `--` a "long" multiple letter option.
> The user can provide optional arguments at the command line in any order they like.
>
> *Positional arguments* have no leading dashes and are not optional - the user
> must provide them at the command line in the order in which they are defined
> (the exception being if `nargs='?'`, which we saw earlier).

### Collating results

Now that we've got word counts for a number of books,
we may want to collate the word counts.
Using the same template as before,
we can write the following script called `collate.py`:

```python
"""Combine multiple word count CSV-files into a single cumulative count."""
import sys
import csv
import argparse
from collections import Counter


def collection_to_csv(collection, ntop=None):
    """Write out a collection of items and counts in csv format."""
    collection = collection.most_common()
    limit = ntop if ntop else len(collection)
    writer = csv.writer(sys.stdout)
    writer.writerows(collection[0:limit])


def update_counts(reader, word_counts):
    """Update word counts with data from another reader/file."""
    for word, count in csv.reader(reader):
        word_counts[word] += int(count)


def main(args):
    """Run the command line program."""
    word_counts = Counter()
    for fn in args.infiles:
        with open(fn, 'r') as reader:
            update_counts(reader, word_counts)
    collection_to_csv(word_counts, ntop=args.ntop)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('infiles', type=str, nargs='*', help='Input file names')
    parser.add_argument('-n', '--ntop', type=int, default=None,
                        help='Limit output to n most frequent words')
    args = parser.parse_args()
    main(args)
```

It will take an arbitrary number of input files generated using `countwords.py`
and collate the word counts:

```shell
$ python collate.py ../results/dracula.csv ../results/moby_dick.csv ../results/emma.csv -n 10
```

```text
the,26450
and,16686
of,14793
to,14554
a,10664
I,10144
in,8637
that,7173
it,6171
was,5891
```

### Writing your own modules

You might have noticed the duplication between `countwords.py` and `collate.py` --
both use the function `collection_to_csv`.
Having the same function in numerous different scripts is inefficient and error prone.
For instance,
if we want to make an improvement to `collection_to_csv` in the future,
we have to find every single script that we've copy and pasted it into.
To avoid this situation,
let's create a module (i.e. a file with a bunch of Python functions in it)
called `mymodule.py` for our commonly used functions:

```python
"""
Collection of commonly used functions.

Functions
---------
collection_to_csv
    write out a collection of items and counts in csv format
"""
import sys
import csv

def collection_to_csv(collection, ntop=None):
    """
    Write out a collection of items and counts in csv format.

    Parameters
    ----------
    collection : collections.Counter
        Collection of items and counts
    ntop : int
        Limit output to n most frequent items
    """
    collection = collection.most_common()
    limit = ntop if ntop else len(collection)
    writer = csv.writer(sys.stdout)
    writer.writerows(collection[0:limit])
```

(You'll see we've also taken the time to improve the docstring for `collection_to_csv`.)

We can now import that function into our scripts,
rather than having to define it anew every time.
We either import the entire module with `import mymodule`
or just the function of interest with `from mymodule import collection_to_csv`.
Here's our new `countwords.py` script,

```python
"""Count the occurrences of all words in a text and write them to a CSV-file."""
import re
import argparse
from collections import Counter
import mymodule


def count_words(reader):
    """Count the occurrence of each word in a string."""
    text = reader.read()
    findwords = re.compile(r"\w+", re.IGNORECASE)
    word_list = re.findall(findwords, text)
    word_counts = Counter(word_list)
    return word_counts


def main(args):
    """Run the command line program."""
    with args.infile as reader:
        word_counts = count_words(reader)
    mymodule.collection_to_csv(word_counts, ntop=args.ntop)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('infile', type=argparse.FileType('r'), nargs='?',
                        default='-', help='Input file name')
    parser.add_argument('-n', '--ntop', type=int, default=None,
                        help='Limit output to n most frequent words')
    args = parser.parse_args()
    main(args)
```

and here's the updated `collate.py`:

```python
"""Combine multiple word count CSV-files into a single cumulative count."""
import csv
import argparse
from collections import Counter
import mymodule


def update_counts(reader, word_counts):
    """Update word counts with data from another reader/file."""
    for word, count in csv.reader(reader):
        word_counts[word] += int(count)


def main(args):
    """Run the command line program."""
    word_counts = Counter()
    for fn in args.infiles:
        with open(fn, 'r') as reader:
            update_counts(reader, word_counts)
    mymodule.collection_to_csv(word_counts, ntop=args.ntop)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('infiles', type=str, nargs='*', help='Input file names')
    parser.add_argument('-n', '--ntop', type=int, default=None,
                        help='Limit output to n most frequent words')
    args = parser.parse_args()
    main(args)
```

## Mission Critical Exercise {#py-rse-py-scripting-critical-exercise}

The last thing for us to do is to plot the word count distribution.

Recall that [Zipf's law][zipfs-law] states the second most common word in a body of text
appears half as often as the most common,
the third most common appears a third as often, and so on.
Mathematically, this might be written as
"word frequency is proportional to 1/rank."

The following code plots the word frequency against the inverse rank
using the popular pandas library:

```python
import pandas
import matplotlib.pyplot as plt


input_csv = '../results/emma.csv'
df = pd.read_csv(input_csv, header=None, names=('word', 'word_frequency'))
df['rank'] = df['word_frequency'].rank(ascending=False)
df['inverse_rank'] = 1 / df['rank']
df.plot.scatter(x='word_frequency', y='inverse_rank',
                figsize=[12, 6], grid=True)
plt.show()
```

```{r py-rse-py-scripting-repl, echo=FALSE, fig.cap="Word frequency distribution for the book Emma"}
knitr::include_graphics("figures/py-rse-scripting/emma.png")
```

Using `script_template.py` as a guide,
take this plotting code and write a new python script called `plotcounts.py`.
The script should:

a. Use the `type=argparse.FileType('r')`, `nargs='?'` and `default='-'` options
   for the input file argument (i.e. similar to the `countwords.py` script)
   so that `plotcounts.py` uses standard input if no csv file is given.

b. Include an optional `--outfile` argument for the name of the output image file.
   The default value should be `plotcounts.png`.

b. Include an optional `--xlim` argument so that the user can change the x-axis bounds.

Once you've written `plotcounts.py`,
generate a plot of the word counts for *Emma*:

```shell
$ python plotcounts.py ../results/emma.csv --outfile ../results/emma.png
```


## Summary {#py-rse-py-scripting-summary}

In the novice lessons,
we learned how to reuse (rather than cut and paste)
code by defining functions.
In order to use those functions in other python notebooks/scripts,
we can save them in a file (called a module) that can be imported.
In this chapter we have seen that we can go one step further
and run our Python code outside of a Python environment,
by writing Python scripts that can be executed at the command line.


## Exercises {#py-rse-py-scripting-exercises}

TODO

## Key Points {#py-rse-py-scripting-keypoints}

```{r, child="keypoints/py-rse-scripting.md"}
```

```{r, child="./links.md"}
```
