# Command Line Programs in Python {#py-rse-py-scripting}

The Jupyter Notebook, PyCharm and other graphical interfaces
are great for prototyping code and exploring data,
but in many cases we ultimately need to apply our code to thousands of data files,
run it with many different parameters,
or combine it with other programs in a data analysis pipeline.
The easiest way to do this effectively is often
to turn our code into a standalone program that can be run in the Unix shell
just like other command-line tools [@Tasc2017].

In this chapter we will develop a command-line Python program
that can be controlled by several option flags,
handles input and output in ways that other command-line tools expect,
and provides useful information when things go wrong.
The result will have more scaffolding than useful application code,
but that scaffolding stays more or less the same as programs get larger.

## How can I tell if my code is a program or a module? {#py-rse-py-scripting-main}

If we are going to run a Python program from the command line,
the first thing we should do is add this to the bottom of the file:

```python
if __name__ == '__main__':
    main()
```

These two lines of code differentiate between
running a Python file as a standalone program
and importing it as a module.
When we import a Python file as a module in another program,
the `__name__` variable is automatically set to the name of the file:
for example,
if we run:

```python
import utilities
```

then for the code inside `utilities.py`,
`__name__` is `utilities`.
When we run a Python file as a standalone program,
on the other hand,
`__name__` is always set to the special string `"__main__"`.
This means that we can separate the two cases above
by checking the value of the variable `__name__`.
If that tells us that the file is running as a standalone program,
we can then handle command-line options, print help, or whatever else is appropriate.
Conventionally,
we define this functionality inside a function called `main`,
but we can call it whatever we want.
(We can also put this code directly under the `if` statement,
but that's generally considered bad practice,
since it makes testing harder.)

## How can I handle command-line options? {#py-rse-py-scripting-options}

The next thing we need is
a library to parse any options given to the program on the command line.
The most commonly used library in Python is [`argparse`][argparse],
which can handle options with or without arguments,
convert those arguments from strings to numbers or other types,
display help,
and many other things.

The simplest way to explain how `argparse` works is by example,
so let's create a short Python script called `script_template.py`:

```python
"""One-line description of what the script does."""

import argparse

def main(args):
    """Run the program."""

    print('Input file:', args.infile)
    print('Output file:', args.outfile)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)

    parser.add_argument('infile', type=str, help='Input file name')
    parser.add_argument('outfile', type=str, help='Output file name')

    args = parser.parse_args()
    main(args)
```

When we run `script_template.py` at the command line like this:

```shell
$ python script_template.py in.csv out.png
```

we see that `argparse` handles all the input arguments:

```text
Input file: in.csv
Output file: out.png
```

It also issues errors when users give the program invalid arguments:

```shell
$ python script_template.py in.csv
```

```text
usage: script_template.py [-h] infile outfile
script_template.py: error: the following arguments are required: outfile
```

and automatically generates help to tell us what we did wrong:

```shell
$ python script_template.py -h
```

```text
usage: script_template.py [-h] infile outfile

One-line description of what the script does.

positional arguments:
  infile      Input file name
  outfile     Output file name

optional arguments:
  -h, --help  show this help message and exit
```

As the `--help` hint shows,
`argparse` can handle [long options][long-option-shell] as well as traditional single-letter options;
the [online tutorial][argparse-rse-tutorial] has examples of this and much more.


## A practical example: Zipf's Law analysis {#py-rse-py-scripting-example}

### Counting words

Now that we've got a template for creating Python scripts,
we can go ahead and apply it to the problem of counting words
(and ultimately verifying Zipf's Law) in our collection of classic English novels.

To start,
here's a function that uses the regular expressions (`re`) library
to identify all the words in a text file and then a counter function
from the `collections` library to tally up the occurrence of each word.

```python
import re
from collections import Counter

def count_words(reader):
    """Count the occurrence of each word in a string."""
    text = reader.read()
    findwords = re.compile(r"\w+", re.IGNORECASE)
    word_list = re.findall(findwords, text)
    word_counts = Counter(word_list)

    return word_counts
```

We can apply that function to the Dracula ebook (for example):

```python
with open('../zipfs-law/data/dracula.txt', 'r') as reader:
    word_counts = count_words(reader)

print(word_counts)
```

```text
Counter({'the': 7474, 'and': 5803, 'I': 4846, 'to': 4662, 'of': 3707, 'a': 2955, 'in': 2466, 'that': 2436, 'he': 1996, 'was': 1870, 'it': 1808, 'is': 1498, 'for': 1480, 'as': 1476, 'me': 1452, 'not': 1393, 'his': 1384, 'with': 1283, ...
```

In order to make this function available at the command line,
we basically just need to insert it into the script template developed earlier.
Let's call the script `countwords.py`:

```python
"""Count the occurences of all words in a text and write them to a CSV-file."""

import sys
import re
import argparse
from collections import Counter


def report_results(writer, results):
    """Report results to stream."""
    
    writer = csv.writer(writer)
    for (key, value) in results:
        writer.writerow((key, value))


def count_words(reader):
    """Count the occurrence of each word in a string."""
    text = reader.read()
    findwords = re.compile(r"\w+", re.IGNORECASE)
    word_list = re.findall(findwords, text)
    word_counts = Counter(word_list)

    return word_counts


def main(args):
    """Run the command line program."""
    with args.infile as reader:
        word_counts = count_words(reader)
    word_counts = sort_counts(word_counts, args.sortby)
    report_results(sys.stdout, word_counts, args.n)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('infile', type=argparse.FileType('r'), nargs='?',
                        default='-', help='Input file name')
    parser.add_argument('-n', type=int, default=None,
                        help='Limit output to n most frequent words')
    args = parser.parse_args()
    main(args)
```

The [argparse][argparse] library comes with many different options
for defining the characteristics of command line arguments.
For the `infile` option defined above,
the number of expected arguments (`nargs`) is set to `?`.
This means that one argument (i.e. a file name)
will be consumed from the command line if possible.
The program will read that file
just like the `open('../zipfs-law/data/dracula.txt', 'r')`
command we saw earlier,
because the input `type` has been set to `argparse.FileType('r')`.
The script also defines an optional `-n` flag
(a `-` or `--` denotes an optional argument)
to limit the output so that it's easier to view in our terminal window.
Let's see this in action:

```shell
$ python countwords.py ../data/dracula.txt -n 10
```

```text
the,7474
and,5803
I,4846
to,4662
of,3707
a,2955
in,2466
that,2436
he,1996
```

If we don't provide a file name,
`nargs='?'` dictates that the `default` value of `-` will be used.
The `argparse.FileType('r')` argument type understands the pseudo-argument '-' and
automatically convert this into standard input (`sys.stdin`),
which means the script can participate in a pipeline like
many of the other command line program we've met.
For instance,
this pipeline counts the words in the first 500 lines of the book:

```shell
$ head -500 ../data/dracula.txt | python countwords.py -n 10
```

```text
the,216
and,123
of,114
I,99
to,82
in,54
a,49
was,42
that,41
```

Ultimately,
we want to save the word counts to a CSV file for further analysis and plotting:

```shell
$ python countwords.py ../data/dracula.txt > dracula_words.csv
```

```shell
$ python countwords.py ../data/moby_dick.txt > moby_dick_words.csv
```

```shell
$ python countwords.py ../data/emma.txt > emma_words.csv
```

### Collating results

Now that we've got word counts for a number of books,
we may want to collate the word counts.
Using the same template as before,
we can write the following script called `collate.py`:

```python
"""Combine multiple word count CSV-files into a single cumulative count."""

import sys
import csv
import argparse
from collections import Counter


def report_results(writer, results):
    """Report results to stream."""
    
    writer = csv.writer(writer)
    for (key, value) in results:
        writer.writerow((key, value))


def update_counts(reader, word_counts):
    """Update word counts with data from another reader/file."""
    for (word, count) in csv.reader(reader):
        word_counts[word] += int(count)


def main(args):
    """Run the command line program."""
    word_counts = Counter()
    for fn in args.infiles:
        with open(fn, 'r') as reader:
            update_counts(reader, word_counts)
    report_results(sys.stdout, word_counts)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('infiles', type=str, nargs='*', help='Input file names')
    parser.add_argument('-n', type=int, default=None, help='Limit output to n most frequent words')
    args = parser.parse_args()
    main(args)
```

It will take an arbitrary number of input files generated using `countwords.py`
and collate the word counts:

```shell
$ python collate.py dracula_words.csv moby_dick_words.csv emma_words.csv -n 10
```

```text
the,26450
and,16686
of,14793
to,14554
a,10664
I,10144
in,8637
that,7173
it,6171
was,5891
he,5029
his,4944
```

### Writing your own modules

You might have noticed the duplication between `countwords.py` and `collate.py` --
both use the function `report_results`.
Having the same function in numerous different scripts is inefficient and error prone.
For instance,
if we want to make an improvement to `report_results` in the future,
we have to find every single script that we've copy and pasted it into.
To avoid this situation,
let's create a module (i.e. a file with a bunch of Python functions in it)
called `mymodule.py` for our commonly used functions:

```python
"""Collection of commonly used functions.

Functions:
  report_results  -- report results to stream

"""

import csv

def report_results(writer, results, top_n=None):
    """Report results to stream."""
    
    limit = top_n if top_n else len(results)
    writer = csv.writer(writer)
    for (key, value) in results[0:limit]:
        writer.writerow((key, value))
``` 

We can now import that function into our scripts,
rather than having to define it anew every time.
Here's our new `countwords.py` script,

```python
"""Count the occurences of all words in a text and write them to a CSV-file."""

import sys
import re
import argparse
from collections import Counter
import mymodule


def count_words(reader):
    """Count the occurrence of each word in a string."""
    text = reader.read()
    findwords = re.compile(r"\w+", re.IGNORECASE)
    word_list = re.findall(findwords, text)
    word_counts = Counter(word_list)

    return word_counts


def main(args):
    """Run the command line program."""
    with args.infile as reader:
        word_counts = count_words(reader)
    word_counts = sort_counts(word_counts, args.sortby)
    mymodule.report_results(sys.stdout, word_counts, args.n)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('infile', type=argparse.FileType('r'), nargs='?',
                        default='-', help='Input file name')
    parser.add_argument('-n', type=int, default=None,
                        help='Limit output to n most frequent words')
    args = parser.parse_args()
    main(args)
```

and here's `collate.py`:

```python
"""Combine multiple word count CSV-files into a single cumulative count."""

import sys
import csv
import argparse
from collections import Counter
import mymodule


def update_counts(reader, word_counts):
    """Update word counts with data from another reader/file."""
    for (word, count) in csv.reader(reader):
        word_counts[word] += int(count)


def main(args):
    """Run the command line program."""
    word_counts = Counter()
    for fn in args.infiles:
        with open(fn, 'r') as reader:
            update_counts(reader, word_counts)
    mymodule.report_results(sys.stdout, word_counts)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('infiles', type=str, nargs='*', help='Input file names')
    parser.add_argument('-n', type=int, default=None, help='Limit output to n most frequent words')
    args = parser.parse_args()
    main(args)
```

## Summary {#py-rse-py-scripting-summary}

In the novice lessons,
we learned how to reuse (rather than cut and paste)
code by defining functions.
In order to use those functions in other python notebooks/scripts,
we can save them in a file (called a module) that can be imported.
In this chapter we have seen that we can go one step further
and run our Python code outside of a Python environment,
by writing Python scripts that can be executed at the command line.


## Mission Critical Exercise {#py-rse-py-scripting-critical-exercise}

The last thing for us to do is to plot the word count distribution.

Recall that [Zipf's law][zipfs-law] states the second most common word in a body of text
appears half as often as the most common,
the third most common appears a third as often, and so on.
Mathematically, this might be written as
"word frequency is proportional to 1/rank."

The following code plots the word frequency against the inverse rank 
using the popular pandas library:

```python
import pandas
import matplotlib.pyplot as plt

input_csv = 'emma_words.csv'
df = pd.read_csv(input_csv, header=None, names=('word', 'word_frequency'))
df['rank'] = df['word_frequency'].rank(ascending=False)
df['inverse_rank'] = 1 / df['rank'] 
df.plot.scatter(x='word_frequency', y='inverse_rank',
                figsize=[12, 6], grid=True)
plt.show()
```

```{r py-rse-py-scripting-repl, echo=FALSE, fig.cap="Word frequency distribution for the book Emma"}
knitr::include_graphics("figures/py-rse-scripting/emma_words.png")
```

Using `script_template.py` as a guide,
take this plotting code and write a new python script called `plotcounts.py`.
The script should:

a. Use the `type=argparse.FileType('r')`, `nargs='?'` and `default='-'` options
   for the input file argument (i.e. similar to the `countwords.py` script)
   so that `plotcounts.py` uses standard input if no csv file is given.

b. Add an optional `--xlim` option so that the user can change the x-axis bounds.


## Exercises {#py-rse-py-scripting-exercises}

TODO

## Key Points {#py-rse-py-scripting-keypoints}

```{r, child="keypoints/py-rse-scripting.md"}
```

```{r, child="./links.md"}
```
