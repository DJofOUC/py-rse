# Project Structure {#project}

## Questions {#project-questions}

-   How should I organize the files and directories in my project?

## Objectives {#project-objectives}

```{r, child="objectives/project.md"}
```

## Introduction {#project-intro}

Project organization is like a diet:
there is no such thing as "no diet",
just a good one or a bad one.
Similarly, there is no such thing as "no project organization":
your project is either organized well or poorly.
As with coding style (Chapter \@ref(style)),
small pieces in predictable places with readable names are easier to find and use
than large chunks that vary from project to project
and have names like `stuff`.

TODO: add some more motivation, 
what will a well organized project do for you? 
E.g. make your life easier, make "future you"'s life easier, 
make it easier for other people to understand and contribute.

TODO: use Elizabeth's ideas about this as behavioural change.  
This isn't something you do once and it's done.  
Your daily habits matter.
Plan, communicate the plan, implement the plan, reflect on the plan.

TODO: mimic Elizabeth's data exercise from https://www.ideals.illinois.edu/handle/2142/91611 to look at a couple of projects on GitHub and complete some set tasks.  
Get learners to reflect on what makes it easy to navigate an unfamiliar project.  

TODO: Roadmap for the chapter: 

* What is a project? What should every project have?
* How should I structure the directories and files?
* How should I document data? 

## What *is* a project? {#project-thinking}

This chapter assumes each project is a separate Git repository, 
and "project structure" describes the names, locations (and sometimes content) of the directories and files in this repository.  
But, how do you know what should be considered a project?

[Good enough practices in scientific computing](https://doi.org/10.1371/journal.pcbi.1005510):

> "Like deciding when a chunk of code should be made a function, the ultimate goal of dividing research into distinct projects is to help you and others best understand your work. Some researchers create a separate project for each manuscript they are working on, while others group all research on a common theme, data set, or algorithm into a single project."

> "As a rule of thumb, divide work into projects based on the overlap in data and code files. If 2 research efforts share no data or code, they will probably be easiest to manage independently. If they share more than half of their data and code, they are probably best managed together, while if you are building tools that are used in several projects, the common code should probably be in a project of its own." 

Like features (Chapter \@ref(branches)),
what exactly constitutes a "project" requires a bit of judgment,
and different people will make different decisions.
Some common criteria are one project per publication,
one project per deliverable piece of software,
or one project per team.
The first tends to be too small:
a good data set will result in several reports,
and the goal of some projects is to produce a steady stream of reports (such as monthly forecasts).
The second is a good fit for software engineering projects
whose primary aim is to produce tools rather than results,
but is inappropriate for most data analysis work.
The third tends to be too large:
a team of half a dozen people may work on many different things at once,
and a repository that holds them all quickly looks like someone's basement.

The best rule of thumb we have found for deciding what is and isn't a project
is to ask what you have meetings about.
If the same set of people need to get together on a regular basis to talk about something,
that "something" probably deserves its own repository.
And if the list of people changes slowly over time but the meetings continue,
that's an even stronger sign.

## What files should every project contain? {#project-boilerplate}

TODO: What are the bare minimums here?  I'd say must have `README`, even for your own projects that only live locally.  As soon as something is on GitHub must have `LICENSE` and `CONDUCT`?

Most projects' repositories contain a few files that weren't mentioned in Noble's paper,
but which have become conventional in open source projects.
All of these files may be plain text or Markdown,
and may have a `.txt` or `.md` suffix (or no suffix at all),
but please use the principal names given,
in all caps,
since a growing number of tools expect them.

-   `README`:
    the project's title and a one-paragraph description of its purpose or content.
    This file is displayed by GitHub Pages as the project's home page.

-   `LICENSE`:
    the project's license (discussed in Chapter \@ref(inclusive)).

-   `CONDUCT`:
    its code of conduct
    (also discussed in Chapter \@ref(inclusive)).

-   `CITATION`:
    how the work should be cited.
    This file usually contains a plain text citation,
    and may also include entries formatted for various bibliographic systems like [BibTeX][bibtex].
    Some projects also have a separate `CONTRIBUTORS` file listing everyone who has contributed to it,
    while others include this as a section in `CITATION`.

If setting up the project or contributing to it are complex,
there may also be a file called `BUILD` that explains how to install the required software,
the formatting conventions for new data entries,
and so on.
These instructions can also be included as a section in `README`.
Whichever convention is used,
remember that the easier it is for people to get set up and contribute,
the more likely they are to do so @Stei2014.

TODO: `README` or `CONTRIBUTING` are also great places to document the conventions of structure (the rest of this chapter), naming and style.

## How do I document a project?

TODO: What does someone need to know beyond the collection of files in the project? 
 
TODO: What should go in a `README`? Use Elizabeth's Step 4: "Administrative and personnel details" and "Project information" prompts as a guide. https://www.ideals.illinois.edu/bitstream/handle/2142/91611/W2%20-%20DataDocumentationHandout.docx

## How should I structure the files and directories in my project? 

TODO: "There are many strongly held opinions for how this should be done. These opinions are strongly held not becasue the authors think their way is **the** right way, but because its more important to be consistent, and it's easier to be consistent when you have publicly decreed that *this is* the way you will do something.  Does it matter which you use? Not really.  More important to use a structure that works for you, your audience and your project, be consistent, and communicate your conventions."

TODO: "Here are three examples of opinionated project structure." Design exercise that encourages comparing these structures, what do they have in common? 

[Packaging data analytical work reproducibly using R (and friends)](https://peerj.com/preprints/3192/)

> "1. Organizes files using conventions in the field
> 2. Keep data, method and outputs separate while maintaining the relationship between them."

```
├── DESCRIPTION
├── README.md
├── LICENSE
├── data
│   └── my_data.csv
└── analysis
    └── my_report.Rmd
```

[Good enough practices in scientific computing](https://doi.org/10.1371/journal.pcbi.1005510)

```
├── CITATION
├── README
├── LICENSE 
├── requirements.txt
├── data
│   └──birds_count_table.csv 
├── doc
|   ├── notebook.md
|   ├── manuscript.md
|   └── changelog.txt 
├── results
|   └── summarized_results.csv 
└── src
    ├── sightings_analysis.py 
    └── runall.py
```

https://drivendata.github.io/cookiecutter-data-science/

> "Well organized code tends to be self-documenting in that the organization itself provides context for your code without much overhead."

```
├── LICENSE
├── Makefile           <- Makefile with commands like `make data` or `make train`
├── README.md          <- The top-level README for developers using this project.
├── data
│   ├── external       <- Data from third party sources.
│   ├── interim        <- Intermediate data that has been transformed.
│   ├── processed      <- The final, canonical data sets for modeling.
│   └── raw            <- The original, immutable data dump.
│
├── docs               <- A default Sphinx project; see sphinx-doc.org for details
│
├── models             <- Trained and serialized models, model predictions, or model summaries
│
├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
│                         the creator's initials, and a short `-` delimited description, e.g.
│                         `1.0-jqp-initial-data-exploration`.
│
├── references         <- Data dictionaries, manuals, and all other explanatory materials.
│
├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
│   └── figures        <- Generated graphics and figures to be used in reporting
│
├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
│                         generated with `pip freeze > requirements.txt`
│
├── setup.py           <- Make this project pip installable with `pip install -e`
├── src                <- Source code for use in this project.
│   ├── __init__.py    <- Makes src a Python module
│   │
│   ├── data           <- Scripts to download or generate data
│   │   └── make_dataset.py
│   │
│   ├── features       <- Scripts to turn raw data into features for modeling
│   │   └── build_features.py
│   │
│   ├── models         <- Scripts to train models and then use trained models to make
│   │   │                 predictions
│   │   ├── predict_model.py
│   │   └── train_model.py
│   │
│   └── visualization  <- Scripts to create exploratory and results oriented visualizations
│       └── visualize.py
│
└── tox.ini            <- tox file with settings for running tox; see tox.testrun.org
```

TODO: All different, but follow some general guidelines for a well structured project: 
* split files based on their purpose into directories where the name of the directory indicates the purpose, 
* name files according to their purpose, and/or including important context (e.g. date) in the file name.
* Follow naming conventions for standard files (e.g. README, LICENSE, CITATION)
* Use README files

TODO: Which structure is right for your project?  Borrow from Elizabeth's prompts to "think about and identify an audience and timeline"

TODO: Advantages of adhereing to a structure like one of the ones above: you don't have to document the structure if someone else already has, there might be tools to help you automatically generate the structure, you don't have to remake the decision on every project.

TODO:  "Exercise: Think about a project you have and all the files it it.  What would it look like in one of these structures?"

### What are Noble's Rules? {#project-noble}

TODO: Should this be updated to reflect reccomendations in "Good enough practices in scientific computing"?

@Nobl2009 described a way to organize small bioinformatics projects
that is equally useful for other kinds of research computing.
Each project is put in a separate Git repository,
and the directories in the root of this repository are organized according to purpose.
The original specification included five top-level directories:

-   The `./src/` directory (short for "source") holds source code
    for programs written in languages like C or C++ that need to be compiled.
    Many projects don't have this directory
    because all of their code is written in languages that don't need compilation.
-   Runnable programs go in `./bin/` (an old Unix abbreviation for "binary", meaning "not text").
    This includes the compiled and runnable versions of C and C++ programs,
    and also shell scripts,
    Python or R programs,
    and everything else that can be executed.
-   Raw data goes in in `./data/` and is never modified after being stored.
-   Results are put in `./results/`.
    This includes cleaned-up data,
    figures,
    and everything else that can be rebuilt using what's in `./bin/` and `./data/`.
    If intermediate results can be re-created quickly and easily,
    they might not be stored in version control,
    but anything that is included in a manuscript should be here.
-   Finally,
    documentation and manuscripts go in `./doc/`.

```{r project-noble, echo=FALSE, fig.cap="Project Layout"}
if (knitr::is_latex_output()) {
  knitr::include_graphics("figures/project/noble.pdf")
} else {
  knitr::include_graphics("figures/project/noble.svg")
}
```

Figure \@ref(fig:project-noble) below shows this layout for a project called `g-trans`.
A few things to notice are:

-   The documentation for the `regulate` script appears in the root of `./doc/`,
    while the paper for JCMB is stored in a sub-directory,
    since it contains several files.
-   The `./src/` directory contains a Makefile to re-build the `regulate` program (Chapter \@ref(automate)).
    Some projects put the Makefile in the root directory,
    reasoning that since it affects both `./src/` and `./bin/`,
    it belongs above them both rather than in either one.
-   There are several sub-directories underneath `./data/` and `./results/`,
    which we will discuss in [the next section](#project-filenames).
    Each of the sub-directories in `./results/` has its own Makefile,
    which will re-create the contents of that directory.

## How should files and sub-directories be named? {#project-filenames}

While the directories in the top level of each project are organized by purpose.
the directories within `./data/` and `./results/` are organized chronologically
so that it's easy to see when data was gathered
and when results were generated.
These directories all have names in [ISO date format](glossary.html#iso-date-format) like `YYYY-MM-DD`
to make it easy to sort them chronologically.
This naming is particularly helpful when data and results are used in several reports.

At all levels,
filenames should be easy to match with simple shell wildcards.
For example,
a project might use <code><em>species</em>_<em>organ</em>_<em>treatment</em>.csv</code>
as a file-naming convention,
giving filenames like `human_kidney_cm200.csv`.
This allows `human_*_cm200.csv` to match all human organs
or `*_kidney_*.csv` to match all kidney data.
It does produce long filenames,
but [tab completion](glossary.html#tab-completion) means you only have to type them once.
Long filenames are just as easy to match in programs:
Python's `glob` and R's `Sys.glob` will both take a pattern and return a list of matching filenames.

## How should I manage a mix of compiled programs and scripts? {#project-scripts}

Noble's Rules puts everything runnable in a single directory called `./bin/`.
That makes things easy to find,
but most software engineers would say that only the source code for programs should be in version control,
not the output of the compiler.
There are three ways to handle this:

1.  Put the compiled program under version control.
    In theory this makes research more [reproducible](glossary.html#reproducible-research),
    since anyone who wants to re-run the analysis can be sure they're using exactly the same program as the author,
    but in practice,
    many "compiled" programs load libraries dynamically,
    so their results can still be affected by changes to their environment.
    Putting the compiled programs in version control *does* make it easier for people to re-run analyses,
    though,
    since they don't need to be able to compile things themselves.

2.  Put everything in `./bin/`,
    then edit `.gitignore` to tell Git to ignore the compiled programs.
    This keeps everything runnable in one place,
    but requires a little bit of extra bookkeeping.

3.  Put compiled programs in `./bin/` and everything that doesn't require compilation in `./scripts/`.
    This makes management simpler (just ignore everything in `./bin/`),
    but means there are two places where runnable programs might live.

We usually go with the third option,
but they're all good as long as you are consistent between projects
and [document your rule](#project-boilerplate).

## Should I separate documentation from manuscripts? {#project-docs}

Noble's Rules place documentation and manuscripts in `./docs/`.
As with compiled programs and scripts,
some people separate these,
so that (for example) `./docs/` has the project's website and the documentation for its software,
while `./reports/` has one sub-directory for each paper, thesis chapter, or other manuscript.
As more researchers [work in the open(#g:open-science),
and as tools like [R Markdown][r-markdown] and the [Jupyter Notebook][jupyter]
blur the distinction between software, documentation, and reports,
separating the two makes less sense.

## How should I document my data?

TODO: Why is data special? Why isn't there a section called "How should I document code?", "How should I document my workflow?" Because we assume that these are done explicitly e.g. putting code in a package and using formal documentation or implicitly like using make to document workflow.  There is so much more to know about data than the data itself.

TODO: Re-use Elizabeth's "Activity 1" to get learners thinking about the importance of documentation and metadata. https://www.ideals.illinois.edu/handle/2142/91611

TODO: Use Elizabeth's "Minimum viable documentation" https://www.ideals.illinois.edu/handle/2142/91611

TODO: Focus on documentation data files in repo with README. Re-use Elizabeth's "Activity 1 Step 4": Idenify the relevant sectons for your documentation file, "Data file information"

## How should I handle data can't be stored in version control? {#project-big-data}

Small datasets that don't contain sensitive information can and should be stored in version control.
As a rule of thumb,
anything that you would send in an email attachment is probably small enough to be put into Git,
while anything that might reveal someone's identity when combined with other data sets should not be.

If data is large or sensitive,
there should still be something in `./data/` to show its existence,
and that "something" should be easy for programs to read.
One option is a CSV file whose columns are:

-   the name of the dataset,
-   its URL or other unique identifier,
-   the date it was last checked, and
-   its size (so that users will have some idea of how much work is involved in processing it).

Another option is to have one file per dataset,
so that instead of reading `human_genome.bam`,
the program reads `human_genome.yml` and then uses the `url` key in that file to find the data it actually wants.
If your data is complicated,
you may also want to include a `README.md` file in `./data/` modelled on the one that accompanies
The Pudding article "[Women's Pockets are Inferior][womens-pockets]"
(see Chapter \@ref(publish)).

## Backups 

TODO: SHould we talk about backing up projects?

## Summary {#project-summary}

FIXME: create concept map for project structure

## Exercises {#project-exercises}

FIXME: exercises for structure chapter.

## Key Points {#project-keypoints}

```{r, child="keypoints/project.md"}
```
